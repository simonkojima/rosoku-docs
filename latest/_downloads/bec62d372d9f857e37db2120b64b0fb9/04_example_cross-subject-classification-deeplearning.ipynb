{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Example 04: Cross-subject classification with deep learning\n\nThis example demonstrates **cross-subject motor imagery classification**\nusing a deep learning model with ``rosoku``.\n\nWe use the **Dreyer2023** dataset and train an **EEGNet** model on data pooled\nfrom multiple subjects, then evaluate it on **unseen subjects**. Compared to\nwithin-subject decoding, cross-subject classification is more challenging due to\nlarge inter-subject variability in EEG distributions.\n\nKey aspects illustrated in this example include:\n\n- Loading and preprocessing EEG data from **multiple subjects** using MNE\n- Optional transfer-learning step via **Euclidean alignment**\n  (domain adaptation across subjects)\n- Defining a PyTorch model through a callback (``callback_get_model``) using\n  **braindecode** (EEGNet)\n- Reproducible training via deterministic settings, early stopping, checkpointing,\n  and logging (history, per-trial predictions, normalization parameters, saliency)\n\nThe pipeline consists of the following steps:\n\n1. Load raw EEG recordings for each subject and apply band-pass filtering\n2. Epoch the data and (optionally) apply Euclidean alignment to reduce\n   inter-subject distribution shifts\n3. Concatenate trials across training subjects and train EEGNet\n4. Validate on held-out subjects and use early stopping/checkpointing\n5. Evaluate the final model on unseen test subjects and visualize training curves\n\nThis example is intended as a practical template for building reproducible\ncross-subject deep-learning pipelines for EEG decoding with ``rosoku``.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Simon Kojima <simon.kojima@inria.fr>\n#\n# License: BSD (3-clause)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Set Environment Variables for Replicability\nNOTE:\nThis environment variable MUST be set **before importing torch**.\nIt enforces deterministic behavior in CUDA CuBLAS operations\nwhen `torch.use_deterministic_algorithms(True)` is enabled.\n\nSee:\nhttps://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility\n\nIf this variable is set after importing torch, it will have no effect.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\nos.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Packages\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import functools\nimport numpy as np\nfrom pathlib import Path\nimport mne\nimport pandas as pd\nfrom moabb.datasets import Dreyer2023\nimport torch\nimport braindecode\nimport rosoku"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define a callback function to load ndarray data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def callback_load_ndarray(\n        items,\n        split,\n        tmin,\n        tmax,\n        l_freq,\n        h_freq,\n        order_filter,\n        label_keys,\n        dataset,\n):\n    X_list = []\n    y_list = []\n\n    for item in items:\n        subject = item\n        sessions = dataset.get_data(subjects=[subject])\n        raws = sessions[subject][\"0\"]\n\n        for name, raw in raws.items():\n            raw.filter(\n                l_freq=l_freq,\n                h_freq=h_freq,\n                method=\"iir\",\n                iir_params={\n                    \"ftype\": \"butter\",\n                    \"order\": order_filter,\n                    \"btype\": \"bandpass\",\n                },\n            )\n\n            raw = raw.pick(picks=\"eeg\")\n\n            epochs = mne.Epochs(\n                raw=raw,\n                tmin=tmin,\n                tmax=tmax,\n                baseline=None,\n            ).load_data()\n\n            # Apply Domain Adoptation (Euclidean Alignment)\n            X = rosoku.tl.euclidean_alignment(epochs.get_data())\n\n            y = rosoku.utils.get_labels_from_epochs(epochs, label_keys=label_keys)\n\n            X_list.append(X)\n            y_list.append(y)\n\n    X = np.concatenate(X_list, axis=0)\n    y = np.concatenate(y_list, axis=0)\n\n    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define a callback function to load PyTorch model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def callback_get_model(X, y):\n    _, n_chans, n_times = X.shape\n    F1 = 8\n    D = 2\n    F2 = F1 * D\n\n    model = braindecode.models.EEGNet(\n        n_chans=n_chans,\n        n_outputs=2,\n        n_times=n_times,\n        F1=F1,\n        D=D,\n        F2=F2,\n        drop_prob=0.25,\n    )\n\n    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run the Experiment\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lr = 1e-3\nweight_decay = 1e-2\nn_epochs = 500\nbatch_size = 64\npatience = 75\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nseed = 42\n\ndataset = Dreyer2023()\n\nsave_base = Path(\"~\").expanduser() / \"rosoku-log\"\n(save_base / \"checkpoint\").mkdir(parents=True, exist_ok=True)\n(save_base / \"history\").mkdir(parents=True, exist_ok=True)\n(save_base / \"saliency\").mkdir(parents=True, exist_ok=True)\n(save_base / \"samples\").mkdir(parents=True, exist_ok=True)\n(save_base / \"normalization\").mkdir(parents=True, exist_ok=True)\n\ncriterion = torch.nn.CrossEntropyLoss()\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR\nscheduler_params = {\"T_max\": n_epochs, \"eta_min\": 1e-6}\noptimizer = torch.optim.AdamW\noptimizer_params = {\"lr\": lr, \"weight_decay\": weight_decay}\nearly_stopping = rosoku.utils.EarlyStopping(patience=patience)\n\nlabel_keys = {\"left_hand\": 0, \"right_hand\": 1}\n\nresults = rosoku.deeplearning(\n    items_train=list(range(1, 17)),\n    items_valid=list(range(17, 21)),\n    items_test=[21, 56],\n    callback_load_ndarray=functools.partial(\n        callback_load_ndarray,\n        dataset=dataset,\n        tmin=dataset.interval[0] + 0.5,\n        tmax=dataset.interval[1],\n        l_freq=8.0,\n        h_freq=30.0,\n        order_filter=4,\n        label_keys=label_keys,\n    ),\n    batch_size=batch_size,\n    n_epochs=n_epochs,\n    criterion=criterion,\n    optimizer=optimizer,\n    optimizer_params=optimizer_params,\n    callback_get_model=callback_get_model,\n    scheduler=scheduler,\n    scheduler_params=scheduler_params,\n    device=device,\n    callback_proc_epochs=None,\n    early_stopping=early_stopping,\n    scoring=[\"accuracy\", \"f1\"],\n    history_fname=(save_base / \"history\" / f\"cross-subject-deeplearning.parquet\"),\n    checkpoint_fname=(save_base / \"checkpoint\" / f\"cross-subject-deeplearning.pth\"),\n    samples_fname=(save_base / \"samples\" / f\"cross-subject-deeplearning.parquet\"),\n    normalization_fname=(\n            save_base / \"normalization\" / f\"cross-subject-deeplearning.msgpack\"\n    ),\n    saliency_map_fname=(save_base / \"saliency\" / f\"cross-subject-deeplearning.msgpack\"),\n    label_keys=label_keys,\n    seed=seed,\n    additional_values={\"example_key\": \"example_value\"},\n    use_deterministic_algorithms=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Show Results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(results.to_string())\n\nhistory = pd.read_parquet(save_base / \"history\" / f\"cross-subject-deeplearning.parquet\")\nrosoku.viz.plot_history(history)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}