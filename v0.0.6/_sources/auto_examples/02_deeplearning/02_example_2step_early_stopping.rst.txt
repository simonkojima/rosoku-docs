
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/02_deeplearning/02_example_2step_early_stopping.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_02_deeplearning_02_example_2step_early_stopping.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_02_deeplearning_02_example_2step_early_stopping.py:


Example 01: Within-subject classification with deep learning
============================================================

.. GENERATED FROM PYTHON SOURCE LINES 5-10

.. code-block:: Python


    # Authors: Simon Kojima <simon.kojima@inria.fr>
    #
    # License: BSD (3-clause)








.. GENERATED FROM PYTHON SOURCE LINES 11-13

Import Packages
===============

.. GENERATED FROM PYTHON SOURCE LINES 13-23

.. code-block:: Python

    import functools
    from pathlib import Path
    import mne
    import torch
    import braindecode
    import rosoku

    from moabb.datasets import Dreyer2023









.. GENERATED FROM PYTHON SOURCE LINES 24-26

Define callback functions
=========================

.. GENERATED FROM PYTHON SOURCE LINES 26-97

.. code-block:: Python

    def callback_get_model(X, y):
        _, n_chans, n_times = X.shape
        F1 = 4
        D = 2
        F2 = F1 * D

        model = braindecode.models.EEGNet(
            n_chans=n_chans,
            n_outputs=2,
            n_times=n_times,
            F1=F1,
            D=D,
            F2=F2,
            drop_prob=0.5,
        )

        return model


    def callback_load_epochs(
        items, split, dataset, l_freq, h_freq, order_filter, tmin, tmax
    ):
        subject = items[0]
        items = items[1:]

        sessions = dataset.get_data(subjects=[subject])
        raws_dict = sessions[subject]["0"]

        epochs_list = []

        for name_run, raw in raws_dict.items():
            if not True in [item in name_run for item in items]:
                continue

            raw.filter(
                l_freq=l_freq,
                h_freq=h_freq,
                method="iir",
                iir_params={"ftype": "butter", "order": order_filter, "btype": "bandpass"},
            )

            raw = raw.pick(picks="eeg")

            epochs = mne.Epochs(
                raw=raw,
                tmin=tmin,
                tmax=tmax,
                baseline=None,
            )

            epochs_list.append(epochs)

        return mne.concatenate_epochs(epochs_list)


    def callback_proc_epochs(epochs, split):
        # do nothing in this example
        return epochs


    def convert_epochs_to_ndarray(
        epochs,
        split,
        label_keys,
    ):
        X = epochs.get_data()
        y = rosoku.utils.get_labels_from_epochs(epochs, label_keys)

        return X, y









.. GENERATED FROM PYTHON SOURCE LINES 98-100

Run the Experiment using Early Stopping with Validation data
============================================================

.. GENERATED FROM PYTHON SOURCE LINES 100-170

.. code-block:: Python


    subject = 56
    resample = 128

    lr = 1e-3
    weight_decay = 1e-2
    n_epochs = 500
    batch_size = 4
    patience = 75
    enable_normalization = True
    device = "cuda" if torch.cuda.is_available() else "cpu"

    seed = 42

    dataset = Dreyer2023()

    save_base = Path("~").expanduser() / "rosoku-log"
    (save_base / "checkpoint").mkdir(parents=True, exist_ok=True)
    (save_base / "history").mkdir(parents=True, exist_ok=True)
    (save_base / "saliency").mkdir(parents=True, exist_ok=True)
    (save_base / "samples").mkdir(parents=True, exist_ok=True)
    (save_base / "normalization").mkdir(parents=True, exist_ok=True)

    criterion = torch.nn.CrossEntropyLoss()
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR
    scheduler_params = {"T_max": n_epochs, "eta_min": 1e-6}
    optimizer = torch.optim.AdamW
    optimizer_params = {"lr": lr, "weight_decay": weight_decay}
    early_stopping = rosoku.utils.EarlyStopping(patience=patience)

    label_keys = {"left_hand": 0, "right_hand": 1}

    results_1st_step = rosoku.deeplearning(
        items_train=[subject, "R1", "R2"],
        items_valid=[subject, "R3"],
        items_test=[[subject, "R4", "R5"]],
        callback_load_epochs=functools.partial(
            callback_load_epochs,
            dataset=dataset,
            l_freq=8.0,
            h_freq=30.0,
            order_filter=4,
            tmin=dataset.interval[0] + 0.5,
            tmax=dataset.interval[1],
        ),
        callback_proc_epochs=callback_proc_epochs,
        callback_convert_epochs_to_ndarray=functools.partial(
            convert_epochs_to_ndarray, label_keys=label_keys
        ),
        batch_size=batch_size,
        n_epochs=n_epochs,
        criterion=criterion,
        optimizer=optimizer,
        optimizer_params=optimizer_params,
        callback_get_model=callback_get_model,
        scheduler=scheduler,
        scheduler_params=scheduler_params,
        device=device,
        early_stopping=early_stopping,
        enable_normalization=enable_normalization,
        history_fname=(save_base / "history" / f"sub-{subject}.parquet"),
        checkpoint_fname=(save_base / "checkpoint" / f"sub-{subject}.pth"),
        samples_fname=(save_base / "samples" / f"sub-{subject}.parquet"),
        normalization_fname=(save_base / "normalization" / f"sub-{subject}.msgpack"),
        saliency_map_fname=(save_base / "saliency" / f"sub-{subject}.msgpack"),
        label_keys=label_keys,
        seed=seed,
        additional_values={"subject": subject},
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    0it [00:00, ?it/s]    9it [00:00, 25696.89it/s]
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Filtering raw data in 1 contiguous segment
    Setting up band-pass filter from 8 - 30 Hz

    IIR filter parameters
    ---------------------
    Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:
    - Filter order 16 (effective, after forward-backward)
    - Cutoffs at 8.00, 30.00 Hz: -6.02, -6.02 dB

    Used Annotations descriptions: [np.str_('left_hand'), np.str_('right_hand')]
    Ignoring annotation durations and creating fixed-duration epochs around annotation onsets.
    Not setting metadata
    40 matching events found
    No baseline correction applied
    0 projection items activated
    Filtering raw data in 1 contiguous segment
    Setting up band-pass filter from 8 - 30 Hz

    IIR filter parameters
    ---------------------
    Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:
    - Filter order 16 (effective, after forward-backward)
    - Cutoffs at 8.00, 30.00 Hz: -6.02, -6.02 dB

    Used Annotations descriptions: [np.str_('left_hand'), np.str_('right_hand')]
    Ignoring annotation durations and creating fixed-duration epochs around annotation onsets.
    Not setting metadata
    40 matching events found
    No baseline correction applied
    0 projection items activated
    /home/skojima/git/rosoku/examples/02_deeplearning/02_example_2step_early_stopping.py:78: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.
      return mne.concatenate_epochs(epochs_list)
    Using data from preloaded Raw for 40 events and 2305 original time points ...
    0 bad epochs dropped
    Using data from preloaded Raw for 40 events and 2305 original time points ...
    0 bad epochs dropped
    Using data from preloaded Raw for 40 events and 2305 original time points ...
    Using data from preloaded Raw for 40 events and 2305 original time points ...
    Not setting metadata
    80 matching events found
    No baseline correction applied
    0it [00:00, ?it/s]    9it [00:00, 23548.81it/s]
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Filtering raw data in 1 contiguous segment
    Setting up band-pass filter from 8 - 30 Hz

    IIR filter parameters
    ---------------------
    Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:
    - Filter order 16 (effective, after forward-backward)
    - Cutoffs at 8.00, 30.00 Hz: -6.02, -6.02 dB

    Used Annotations descriptions: [np.str_('left_hand'), np.str_('right_hand')]
    Ignoring annotation durations and creating fixed-duration epochs around annotation onsets.
    Not setting metadata
    40 matching events found
    No baseline correction applied
    0 projection items activated
    /home/skojima/git/rosoku/examples/02_deeplearning/02_example_2step_early_stopping.py:78: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.
      return mne.concatenate_epochs(epochs_list)
    Using data from preloaded Raw for 40 events and 2305 original time points ...
    0 bad epochs dropped
    Using data from preloaded Raw for 40 events and 2305 original time points ...
    Not setting metadata
    40 matching events found
    No baseline correction applied
    0it [00:00, ?it/s]    9it [00:00, 24306.98it/s]
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Filtering raw data in 1 contiguous segment
    Setting up band-pass filter from 8 - 30 Hz

    IIR filter parameters
    ---------------------
    Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:
    - Filter order 16 (effective, after forward-backward)
    - Cutoffs at 8.00, 30.00 Hz: -6.02, -6.02 dB

    Used Annotations descriptions: [np.str_('left_hand'), np.str_('right_hand')]
    Ignoring annotation durations and creating fixed-duration epochs around annotation onsets.
    Not setting metadata
    40 matching events found
    No baseline correction applied
    0 projection items activated
    Filtering raw data in 1 contiguous segment
    Setting up band-pass filter from 8 - 30 Hz

    IIR filter parameters
    ---------------------
    Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:
    - Filter order 16 (effective, after forward-backward)
    - Cutoffs at 8.00, 30.00 Hz: -6.02, -6.02 dB

    Used Annotations descriptions: [np.str_('left_hand'), np.str_('right_hand')]
    Ignoring annotation durations and creating fixed-duration epochs around annotation onsets.
    Not setting metadata
    40 matching events found
    No baseline correction applied
    0 projection items activated
    /home/skojima/git/rosoku/examples/02_deeplearning/02_example_2step_early_stopping.py:78: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.
      return mne.concatenate_epochs(epochs_list)
    Using data from preloaded Raw for 40 events and 2305 original time points ...
    0 bad epochs dropped
    Using data from preloaded Raw for 40 events and 2305 original time points ...
    0 bad epochs dropped
    Using data from preloaded Raw for 40 events and 2305 original time points ...
    Using data from preloaded Raw for 40 events and 2305 original time points ...
    Not setting metadata
    80 matching events found
    No baseline correction applied
    epoch 000, train_loss: 0.6919, train_acc: 0.61, valid_loss: 0.6937, valid_acc: 0.47, lr: 9.9999e-04, et: 0.0650, checkpoint saved
    epoch 001, train_loss: 0.6332, train_acc: 0.68, valid_loss: 0.6948, valid_acc: 0.50, lr: 9.9996e-04, et: 0.0647
    epoch 002, train_loss: 0.6347, train_acc: 0.66, valid_loss: 0.6955, valid_acc: 0.47, lr: 9.9991e-04, et: 0.0656
    epoch 003, train_loss: 0.5997, train_acc: 0.68, valid_loss: 0.6944, valid_acc: 0.47, lr: 9.9984e-04, et: 0.0649
    epoch 004, train_loss: 0.5286, train_acc: 0.78, valid_loss: 0.6924, valid_acc: 0.57, lr: 9.9975e-04, et: 0.0643, checkpoint saved
    epoch 005, train_loss: 0.5075, train_acc: 0.82, valid_loss: 0.6798, valid_acc: 0.57, lr: 9.9965e-04, et: 0.0643, checkpoint saved
    epoch 006, train_loss: 0.4459, train_acc: 0.88, valid_loss: 0.6837, valid_acc: 0.53, lr: 9.9952e-04, et: 0.0607
    epoch 007, train_loss: 0.3751, train_acc: 0.86, valid_loss: 0.6510, valid_acc: 0.55, lr: 9.9937e-04, et: 0.0609, checkpoint saved
    epoch 008, train_loss: 0.3568, train_acc: 0.89, valid_loss: 0.6626, valid_acc: 0.55, lr: 9.9920e-04, et: 0.0611
    epoch 009, train_loss: 0.2593, train_acc: 0.91, valid_loss: 0.6794, valid_acc: 0.55, lr: 9.9901e-04, et: 0.0608
    epoch 010, train_loss: 0.2592, train_acc: 0.91, valid_loss: 0.6534, valid_acc: 0.55, lr: 9.9881e-04, et: 0.0611
    epoch 011, train_loss: 0.2299, train_acc: 0.94, valid_loss: 0.6083, valid_acc: 0.55, lr: 9.9858e-04, et: 0.0614, checkpoint saved
    epoch 012, train_loss: 0.1552, train_acc: 0.96, valid_loss: 0.4209, valid_acc: 0.80, lr: 9.9833e-04, et: 0.0621, checkpoint saved
    epoch 013, train_loss: 0.1337, train_acc: 0.99, valid_loss: 0.3637, valid_acc: 0.82, lr: 9.9807e-04, et: 0.0644, checkpoint saved
    epoch 014, train_loss: 0.2102, train_acc: 0.95, valid_loss: 0.3051, valid_acc: 0.82, lr: 9.9778e-04, et: 0.0653, checkpoint saved
    epoch 015, train_loss: 0.1530, train_acc: 0.94, valid_loss: 0.2539, valid_acc: 0.90, lr: 9.9748e-04, et: 0.0649, checkpoint saved
    epoch 016, train_loss: 0.1723, train_acc: 0.94, valid_loss: 0.2159, valid_acc: 0.93, lr: 9.9715e-04, et: 0.0814, checkpoint saved
    epoch 017, train_loss: 0.1036, train_acc: 0.96, valid_loss: 0.2000, valid_acc: 0.95, lr: 9.9681e-04, et: 0.0757, checkpoint saved
    epoch 018, train_loss: 0.1393, train_acc: 0.94, valid_loss: 0.1957, valid_acc: 0.93, lr: 9.9644e-04, et: 0.1275, checkpoint saved
    epoch 019, train_loss: 0.1155, train_acc: 0.95, valid_loss: 0.2044, valid_acc: 0.95, lr: 9.9606e-04, et: 0.0672
    epoch 020, train_loss: 0.1876, train_acc: 0.93, valid_loss: 0.1976, valid_acc: 0.93, lr: 9.9566e-04, et: 0.0720
    epoch 021, train_loss: 0.1834, train_acc: 0.93, valid_loss: 0.2464, valid_acc: 0.97, lr: 9.9524e-04, et: 0.0657
    epoch 022, train_loss: 0.1553, train_acc: 0.95, valid_loss: 0.2026, valid_acc: 0.90, lr: 9.9479e-04, et: 0.0649
    epoch 023, train_loss: 0.1404, train_acc: 0.96, valid_loss: 0.1941, valid_acc: 0.95, lr: 9.9433e-04, et: 0.0642, checkpoint saved
    epoch 024, train_loss: 0.1131, train_acc: 0.96, valid_loss: 0.1750, valid_acc: 0.95, lr: 9.9385e-04, et: 0.0642, checkpoint saved
    epoch 025, train_loss: 0.1515, train_acc: 0.96, valid_loss: 0.3006, valid_acc: 0.88, lr: 9.9335e-04, et: 0.0638
    epoch 026, train_loss: 0.0913, train_acc: 0.97, valid_loss: 0.2549, valid_acc: 0.90, lr: 9.9283e-04, et: 0.0638
    epoch 027, train_loss: 0.1127, train_acc: 0.96, valid_loss: 0.2194, valid_acc: 0.90, lr: 9.9229e-04, et: 0.0639
    epoch 028, train_loss: 0.0794, train_acc: 0.97, valid_loss: 0.2679, valid_acc: 0.90, lr: 9.9173e-04, et: 0.0650
    epoch 029, train_loss: 0.0667, train_acc: 0.97, valid_loss: 0.1871, valid_acc: 0.93, lr: 9.9115e-04, et: 0.0688
    epoch 030, train_loss: 0.0671, train_acc: 0.99, valid_loss: 0.1950, valid_acc: 0.93, lr: 9.9055e-04, et: 0.0662
    epoch 031, train_loss: 0.0574, train_acc: 0.99, valid_loss: 0.2113, valid_acc: 0.88, lr: 9.8994e-04, et: 0.0659
    epoch 032, train_loss: 0.0818, train_acc: 0.99, valid_loss: 0.2257, valid_acc: 0.88, lr: 9.8930e-04, et: 0.0660
    epoch 033, train_loss: 0.1026, train_acc: 0.95, valid_loss: 0.2036, valid_acc: 0.93, lr: 9.8865e-04, et: 0.0654
    epoch 034, train_loss: 0.1489, train_acc: 0.95, valid_loss: 0.2954, valid_acc: 0.88, lr: 9.8797e-04, et: 0.0646
    epoch 035, train_loss: 0.1411, train_acc: 0.96, valid_loss: 0.2489, valid_acc: 0.88, lr: 9.8728e-04, et: 0.0641
    epoch 036, train_loss: 0.1073, train_acc: 0.97, valid_loss: 0.1989, valid_acc: 0.95, lr: 9.8656e-04, et: 0.0646
    epoch 037, train_loss: 0.2400, train_acc: 0.93, valid_loss: 0.2263, valid_acc: 0.93, lr: 9.8583e-04, et: 0.0642
    epoch 038, train_loss: 0.1861, train_acc: 0.94, valid_loss: 0.2124, valid_acc: 0.93, lr: 9.8508e-04, et: 0.0644
    epoch 039, train_loss: 0.1216, train_acc: 0.96, valid_loss: 0.3105, valid_acc: 0.85, lr: 9.8431e-04, et: 0.0645
    epoch 040, train_loss: 0.0605, train_acc: 1.00, valid_loss: 0.3991, valid_acc: 0.85, lr: 9.8352e-04, et: 0.0645
    epoch 041, train_loss: 0.0527, train_acc: 0.99, valid_loss: 0.3097, valid_acc: 0.85, lr: 9.8271e-04, et: 0.0651
    epoch 042, train_loss: 0.1835, train_acc: 0.94, valid_loss: 0.2783, valid_acc: 0.93, lr: 9.8188e-04, et: 0.0647
    epoch 043, train_loss: 0.0590, train_acc: 0.99, valid_loss: 0.3222, valid_acc: 0.88, lr: 9.8103e-04, et: 0.0651
    epoch 044, train_loss: 0.0856, train_acc: 0.97, valid_loss: 0.2762, valid_acc: 0.85, lr: 9.8017e-04, et: 0.0655
    epoch 045, train_loss: 0.0951, train_acc: 0.96, valid_loss: 0.2635, valid_acc: 0.90, lr: 9.7928e-04, et: 0.0649
    epoch 046, train_loss: 0.0336, train_acc: 0.99, valid_loss: 0.2757, valid_acc: 0.90, lr: 9.7838e-04, et: 0.0652
    epoch 047, train_loss: 0.0477, train_acc: 1.00, valid_loss: 0.2971, valid_acc: 0.93, lr: 9.7745e-04, et: 0.0657
    epoch 048, train_loss: 0.1386, train_acc: 0.95, valid_loss: 0.3489, valid_acc: 0.88, lr: 9.7651e-04, et: 0.0649
    epoch 049, train_loss: 0.1192, train_acc: 0.94, valid_loss: 0.3810, valid_acc: 0.82, lr: 9.7555e-04, et: 0.0645
    epoch 050, train_loss: 0.1212, train_acc: 0.96, valid_loss: 0.3801, valid_acc: 0.88, lr: 9.7457e-04, et: 0.0648
    epoch 051, train_loss: 0.1911, train_acc: 0.93, valid_loss: 0.3016, valid_acc: 0.85, lr: 9.7358e-04, et: 0.0647
    epoch 052, train_loss: 0.0620, train_acc: 0.97, valid_loss: 0.3264, valid_acc: 0.85, lr: 9.7256e-04, et: 0.0646
    epoch 053, train_loss: 0.0747, train_acc: 0.96, valid_loss: 0.3431, valid_acc: 0.85, lr: 9.7152e-04, et: 0.0648
    epoch 054, train_loss: 0.0549, train_acc: 0.99, valid_loss: 0.3228, valid_acc: 0.88, lr: 9.7047e-04, et: 0.0641
    epoch 055, train_loss: 0.0371, train_acc: 0.99, valid_loss: 0.3160, valid_acc: 0.85, lr: 9.6940e-04, et: 0.0642
    epoch 056, train_loss: 0.0562, train_acc: 0.99, valid_loss: 0.3042, valid_acc: 0.82, lr: 9.6831e-04, et: 0.0654
    epoch 057, train_loss: 0.0767, train_acc: 0.96, valid_loss: 0.3371, valid_acc: 0.80, lr: 9.6720e-04, et: 0.0641
    epoch 058, train_loss: 0.0692, train_acc: 0.99, valid_loss: 0.3156, valid_acc: 0.90, lr: 9.6607e-04, et: 0.0648
    epoch 059, train_loss: 0.0341, train_acc: 0.99, valid_loss: 0.3008, valid_acc: 0.93, lr: 9.6492e-04, et: 0.0655
    epoch 060, train_loss: 0.1689, train_acc: 0.94, valid_loss: 0.3612, valid_acc: 0.88, lr: 9.6376e-04, et: 0.0655
    epoch 061, train_loss: 0.0823, train_acc: 0.97, valid_loss: 0.3327, valid_acc: 0.90, lr: 9.6258e-04, et: 0.0652
    epoch 062, train_loss: 0.2053, train_acc: 0.95, valid_loss: 0.3068, valid_acc: 0.88, lr: 9.6138e-04, et: 0.0652
    epoch 063, train_loss: 0.0209, train_acc: 1.00, valid_loss: 0.2504, valid_acc: 0.90, lr: 9.6016e-04, et: 0.0653
    epoch 064, train_loss: 0.0543, train_acc: 0.99, valid_loss: 0.2414, valid_acc: 0.90, lr: 9.5892e-04, et: 0.0651
    epoch 065, train_loss: 0.0651, train_acc: 0.97, valid_loss: 0.2410, valid_acc: 0.90, lr: 9.5766e-04, et: 0.0645
    epoch 066, train_loss: 0.0290, train_acc: 1.00, valid_loss: 0.2477, valid_acc: 0.93, lr: 9.5639e-04, et: 0.0642
    epoch 067, train_loss: 0.0583, train_acc: 0.99, valid_loss: 0.2426, valid_acc: 0.93, lr: 9.5510e-04, et: 0.0653
    epoch 068, train_loss: 0.0173, train_acc: 1.00, valid_loss: 0.2280, valid_acc: 0.90, lr: 9.5379e-04, et: 0.0642
    epoch 069, train_loss: 0.0332, train_acc: 1.00, valid_loss: 0.2089, valid_acc: 0.93, lr: 9.5246e-04, et: 0.0643
    epoch 070, train_loss: 0.0460, train_acc: 0.99, valid_loss: 0.2061, valid_acc: 0.93, lr: 9.5112e-04, et: 0.0649
    epoch 071, train_loss: 0.0123, train_acc: 1.00, valid_loss: 0.2319, valid_acc: 0.93, lr: 9.4975e-04, et: 0.0645
    epoch 072, train_loss: 0.0275, train_acc: 0.99, valid_loss: 0.2143, valid_acc: 0.93, lr: 9.4837e-04, et: 0.0719
    epoch 073, train_loss: 0.0228, train_acc: 1.00, valid_loss: 0.2011, valid_acc: 0.93, lr: 9.4697e-04, et: 0.0647
    epoch 074, train_loss: 0.0889, train_acc: 0.95, valid_loss: 0.2250, valid_acc: 0.93, lr: 9.4556e-04, et: 0.0680
    epoch 075, train_loss: 0.0666, train_acc: 0.96, valid_loss: 0.3259, valid_acc: 0.85, lr: 9.4412e-04, et: 0.0647
    epoch 076, train_loss: 0.1659, train_acc: 0.95, valid_loss: 0.2696, valid_acc: 0.90, lr: 9.4267e-04, et: 0.0668
    epoch 077, train_loss: 0.0230, train_acc: 1.00, valid_loss: 0.2733, valid_acc: 0.90, lr: 9.4120e-04, et: 0.0685
    epoch 078, train_loss: 0.0781, train_acc: 0.95, valid_loss: 0.2967, valid_acc: 0.88, lr: 9.3972e-04, et: 0.0646
    epoch 079, train_loss: 0.0436, train_acc: 0.97, valid_loss: 0.3071, valid_acc: 0.90, lr: 9.3822e-04, et: 0.0644
    epoch 080, train_loss: 0.0232, train_acc: 0.99, valid_loss: 0.2752, valid_acc: 0.93, lr: 9.3669e-04, et: 0.0644
    epoch 081, train_loss: 0.0832, train_acc: 0.96, valid_loss: 0.3039, valid_acc: 0.93, lr: 9.3516e-04, et: 0.0647
    epoch 082, train_loss: 0.0246, train_acc: 1.00, valid_loss: 0.2704, valid_acc: 0.93, lr: 9.3360e-04, et: 0.0650
    epoch 083, train_loss: 0.0833, train_acc: 0.96, valid_loss: 0.3484, valid_acc: 0.90, lr: 9.3203e-04, et: 0.0651
    epoch 084, train_loss: 0.0479, train_acc: 1.00, valid_loss: 0.3210, valid_acc: 0.90, lr: 9.3044e-04, et: 0.0637
    epoch 085, train_loss: 0.0595, train_acc: 0.97, valid_loss: 0.2855, valid_acc: 0.95, lr: 9.2883e-04, et: 0.0647
    epoch 086, train_loss: 0.0506, train_acc: 0.97, valid_loss: 0.2362, valid_acc: 0.90, lr: 9.2721e-04, et: 0.0642
    epoch 087, train_loss: 0.0510, train_acc: 0.99, valid_loss: 0.2305, valid_acc: 0.95, lr: 9.2557e-04, et: 0.0652
    epoch 088, train_loss: 0.1621, train_acc: 0.94, valid_loss: 0.2736, valid_acc: 0.90, lr: 9.2392e-04, et: 0.0645
    epoch 089, train_loss: 0.0703, train_acc: 0.97, valid_loss: 0.2126, valid_acc: 0.90, lr: 9.2224e-04, et: 0.0659
    epoch 090, train_loss: 0.0496, train_acc: 1.00, valid_loss: 0.1718, valid_acc: 0.93, lr: 9.2055e-04, et: 0.0673, checkpoint saved
    epoch 091, train_loss: 0.0587, train_acc: 0.96, valid_loss: 0.2098, valid_acc: 0.93, lr: 9.1885e-04, et: 0.0670
    epoch 092, train_loss: 0.0133, train_acc: 1.00, valid_loss: 0.1894, valid_acc: 0.90, lr: 9.1712e-04, et: 0.0649
    epoch 093, train_loss: 0.0093, train_acc: 1.00, valid_loss: 0.1842, valid_acc: 0.90, lr: 9.1538e-04, et: 0.0660
    epoch 094, train_loss: 0.0478, train_acc: 0.99, valid_loss: 0.2066, valid_acc: 0.90, lr: 9.1363e-04, et: 0.0647
    epoch 095, train_loss: 0.0230, train_acc: 1.00, valid_loss: 0.2147, valid_acc: 0.93, lr: 9.1185e-04, et: 0.0642
    epoch 096, train_loss: 0.0257, train_acc: 1.00, valid_loss: 0.2214, valid_acc: 0.90, lr: 9.1007e-04, et: 0.0668
    epoch 097, train_loss: 0.0161, train_acc: 1.00, valid_loss: 0.2076, valid_acc: 0.93, lr: 9.0826e-04, et: 0.0648
    epoch 098, train_loss: 0.0518, train_acc: 0.99, valid_loss: 0.2454, valid_acc: 0.90, lr: 9.0644e-04, et: 0.0639
    epoch 099, train_loss: 0.0897, train_acc: 0.95, valid_loss: 0.2843, valid_acc: 0.90, lr: 9.0460e-04, et: 0.0651
    epoch 100, train_loss: 0.0593, train_acc: 0.97, valid_loss: 0.2618, valid_acc: 0.93, lr: 9.0275e-04, et: 0.0647
    epoch 101, train_loss: 0.0818, train_acc: 0.96, valid_loss: 0.2470, valid_acc: 0.90, lr: 9.0088e-04, et: 0.0645
    epoch 102, train_loss: 0.0415, train_acc: 0.99, valid_loss: 0.2728, valid_acc: 0.88, lr: 8.9900e-04, et: 0.0671
    epoch 103, train_loss: 0.1165, train_acc: 0.94, valid_loss: 0.2420, valid_acc: 0.88, lr: 8.9710e-04, et: 0.0641
    epoch 104, train_loss: 0.0842, train_acc: 0.99, valid_loss: 0.2636, valid_acc: 0.93, lr: 8.9518e-04, et: 0.0653
    epoch 105, train_loss: 0.0461, train_acc: 0.99, valid_loss: 0.2792, valid_acc: 0.93, lr: 8.9325e-04, et: 0.0668
    epoch 106, train_loss: 0.1048, train_acc: 0.96, valid_loss: 0.2532, valid_acc: 0.90, lr: 8.9130e-04, et: 0.0647
    epoch 107, train_loss: 0.0490, train_acc: 0.97, valid_loss: 0.2562, valid_acc: 0.90, lr: 8.8934e-04, et: 0.0659
    epoch 108, train_loss: 0.1171, train_acc: 0.94, valid_loss: 0.3507, valid_acc: 0.85, lr: 8.8736e-04, et: 0.0662
    epoch 109, train_loss: 0.0629, train_acc: 0.96, valid_loss: 0.4671, valid_acc: 0.82, lr: 8.8537e-04, et: 0.0645
    epoch 110, train_loss: 0.0409, train_acc: 0.97, valid_loss: 0.3479, valid_acc: 0.90, lr: 8.8336e-04, et: 0.0649
    epoch 111, train_loss: 0.0545, train_acc: 0.99, valid_loss: 0.1982, valid_acc: 0.93, lr: 8.8134e-04, et: 0.0642
    epoch 112, train_loss: 0.0326, train_acc: 0.99, valid_loss: 0.1739, valid_acc: 0.93, lr: 8.7930e-04, et: 0.0640
    epoch 113, train_loss: 0.0149, train_acc: 1.00, valid_loss: 0.1648, valid_acc: 0.93, lr: 8.7725e-04, et: 0.0645, checkpoint saved
    epoch 114, train_loss: 0.0294, train_acc: 0.97, valid_loss: 0.1836, valid_acc: 0.90, lr: 8.7518e-04, et: 0.0640
    epoch 115, train_loss: 0.0086, train_acc: 1.00, valid_loss: 0.1922, valid_acc: 0.90, lr: 8.7310e-04, et: 0.0647
    epoch 116, train_loss: 0.0456, train_acc: 0.99, valid_loss: 0.2136, valid_acc: 0.93, lr: 8.7100e-04, et: 0.0645
    epoch 117, train_loss: 0.0204, train_acc: 1.00, valid_loss: 0.1945, valid_acc: 0.93, lr: 8.6889e-04, et: 0.0646
    epoch 118, train_loss: 0.0517, train_acc: 0.99, valid_loss: 0.2060, valid_acc: 0.90, lr: 8.6676e-04, et: 0.0648
    epoch 119, train_loss: 0.0278, train_acc: 0.99, valid_loss: 0.2103, valid_acc: 0.90, lr: 8.6462e-04, et: 0.0647
    epoch 120, train_loss: 0.0811, train_acc: 0.97, valid_loss: 0.2652, valid_acc: 0.88, lr: 8.6246e-04, et: 0.0648
    epoch 121, train_loss: 0.0215, train_acc: 1.00, valid_loss: 0.2750, valid_acc: 0.90, lr: 8.6029e-04, et: 0.0653
    epoch 122, train_loss: 0.0393, train_acc: 0.97, valid_loss: 0.2859, valid_acc: 0.90, lr: 8.5811e-04, et: 0.0657
    epoch 123, train_loss: 0.0106, train_acc: 1.00, valid_loss: 0.2705, valid_acc: 0.90, lr: 8.5591e-04, et: 0.0639
    epoch 124, train_loss: 0.0684, train_acc: 0.97, valid_loss: 0.2403, valid_acc: 0.88, lr: 8.5370e-04, et: 0.0650
    epoch 125, train_loss: 0.0125, train_acc: 1.00, valid_loss: 0.2053, valid_acc: 0.93, lr: 8.5147e-04, et: 0.0644
    epoch 126, train_loss: 0.0211, train_acc: 0.99, valid_loss: 0.1966, valid_acc: 0.90, lr: 8.4923e-04, et: 0.0660
    epoch 127, train_loss: 0.0425, train_acc: 0.99, valid_loss: 0.2788, valid_acc: 0.85, lr: 8.4698e-04, et: 0.0642
    epoch 128, train_loss: 0.1572, train_acc: 0.95, valid_loss: 0.2709, valid_acc: 0.90, lr: 8.4471e-04, et: 0.0641
    epoch 129, train_loss: 0.0627, train_acc: 0.97, valid_loss: 0.2590, valid_acc: 0.82, lr: 8.4243e-04, et: 0.0645
    epoch 130, train_loss: 0.0448, train_acc: 0.99, valid_loss: 0.2959, valid_acc: 0.85, lr: 8.4014e-04, et: 0.0643
    epoch 131, train_loss: 0.0683, train_acc: 0.97, valid_loss: 0.2596, valid_acc: 0.88, lr: 8.3783e-04, et: 0.0638
    epoch 132, train_loss: 0.0317, train_acc: 0.99, valid_loss: 0.2473, valid_acc: 0.90, lr: 8.3551e-04, et: 0.0639
    epoch 133, train_loss: 0.0822, train_acc: 0.96, valid_loss: 0.2625, valid_acc: 0.88, lr: 8.3317e-04, et: 0.0643
    epoch 134, train_loss: 0.0076, train_acc: 1.00, valid_loss: 0.2548, valid_acc: 0.90, lr: 8.3083e-04, et: 0.0641
    epoch 135, train_loss: 0.0815, train_acc: 0.97, valid_loss: 0.2572, valid_acc: 0.90, lr: 8.2846e-04, et: 0.0641
    epoch 136, train_loss: 0.0123, train_acc: 1.00, valid_loss: 0.2419, valid_acc: 0.90, lr: 8.2609e-04, et: 0.0652
    epoch 137, train_loss: 0.0222, train_acc: 1.00, valid_loss: 0.2403, valid_acc: 0.90, lr: 8.2370e-04, et: 0.0644
    epoch 138, train_loss: 0.0593, train_acc: 0.99, valid_loss: 0.1999, valid_acc: 0.90, lr: 8.2131e-04, et: 0.0646
    epoch 139, train_loss: 0.0169, train_acc: 1.00, valid_loss: 0.1987, valid_acc: 0.90, lr: 8.1889e-04, et: 0.0642
    epoch 140, train_loss: 0.0362, train_acc: 0.97, valid_loss: 0.2068, valid_acc: 0.90, lr: 8.1647e-04, et: 0.0644
    epoch 141, train_loss: 0.0076, train_acc: 1.00, valid_loss: 0.2359, valid_acc: 0.90, lr: 8.1403e-04, et: 0.0642
    epoch 142, train_loss: 0.0146, train_acc: 1.00, valid_loss: 0.2158, valid_acc: 0.90, lr: 8.1158e-04, et: 0.0638
    epoch 143, train_loss: 0.0460, train_acc: 0.97, valid_loss: 0.2385, valid_acc: 0.90, lr: 8.0912e-04, et: 0.0642
    epoch 144, train_loss: 0.1858, train_acc: 0.96, valid_loss: 0.3266, valid_acc: 0.85, lr: 8.0665e-04, et: 0.0643
    epoch 145, train_loss: 0.0472, train_acc: 0.99, valid_loss: 0.3072, valid_acc: 0.88, lr: 8.0416e-04, et: 0.0642
    epoch 146, train_loss: 0.0369, train_acc: 0.97, valid_loss: 0.2725, valid_acc: 0.90, lr: 8.0166e-04, et: 0.0640
    epoch 147, train_loss: 0.0504, train_acc: 0.96, valid_loss: 0.3240, valid_acc: 0.90, lr: 7.9915e-04, et: 0.0639
    epoch 148, train_loss: 0.0182, train_acc: 1.00, valid_loss: 0.3232, valid_acc: 0.90, lr: 7.9663e-04, et: 0.0640
    epoch 149, train_loss: 0.0697, train_acc: 0.96, valid_loss: 0.3354, valid_acc: 0.90, lr: 7.9410e-04, et: 0.0645
    epoch 150, train_loss: 0.0318, train_acc: 1.00, valid_loss: 0.3435, valid_acc: 0.88, lr: 7.9155e-04, et: 0.0645
    epoch 151, train_loss: 0.0187, train_acc: 1.00, valid_loss: 0.3294, valid_acc: 0.88, lr: 7.8900e-04, et: 0.0640
    epoch 152, train_loss: 0.0179, train_acc: 1.00, valid_loss: 0.3018, valid_acc: 0.93, lr: 7.8643e-04, et: 0.0644
    epoch 153, train_loss: 0.0150, train_acc: 1.00, valid_loss: 0.2833, valid_acc: 0.93, lr: 7.8385e-04, et: 0.0641
    epoch 154, train_loss: 0.0622, train_acc: 0.96, valid_loss: 0.2102, valid_acc: 0.93, lr: 7.8126e-04, et: 0.0691
    epoch 155, train_loss: 0.0733, train_acc: 0.97, valid_loss: 0.1782, valid_acc: 0.93, lr: 7.7866e-04, et: 0.0637
    epoch 156, train_loss: 0.0122, train_acc: 1.00, valid_loss: 0.1620, valid_acc: 0.93, lr: 7.7605e-04, et: 0.0638, checkpoint saved
    epoch 157, train_loss: 0.0179, train_acc: 1.00, valid_loss: 0.1631, valid_acc: 0.93, lr: 7.7342e-04, et: 0.0640
    epoch 158, train_loss: 0.0122, train_acc: 1.00, valid_loss: 0.1734, valid_acc: 0.90, lr: 7.7079e-04, et: 0.0639
    epoch 159, train_loss: 0.1379, train_acc: 0.96, valid_loss: 0.2560, valid_acc: 0.93, lr: 7.6815e-04, et: 0.0639
    epoch 160, train_loss: 0.0980, train_acc: 0.94, valid_loss: 0.2989, valid_acc: 0.88, lr: 7.6549e-04, et: 0.0654
    epoch 161, train_loss: 0.0691, train_acc: 0.97, valid_loss: 0.2787, valid_acc: 0.90, lr: 7.6282e-04, et: 0.0646
    epoch 162, train_loss: 0.0075, train_acc: 1.00, valid_loss: 0.2654, valid_acc: 0.93, lr: 7.6015e-04, et: 0.0639
    epoch 163, train_loss: 0.0213, train_acc: 0.99, valid_loss: 0.2667, valid_acc: 0.93, lr: 7.5746e-04, et: 0.0641
    epoch 164, train_loss: 0.0362, train_acc: 1.00, valid_loss: 0.2809, valid_acc: 0.90, lr: 7.5477e-04, et: 0.0645
    epoch 165, train_loss: 0.0333, train_acc: 0.99, valid_loss: 0.2605, valid_acc: 0.90, lr: 7.5206e-04, et: 0.0639
    epoch 166, train_loss: 0.0146, train_acc: 1.00, valid_loss: 0.2539, valid_acc: 0.90, lr: 7.4934e-04, et: 0.0644
    epoch 167, train_loss: 0.0388, train_acc: 0.97, valid_loss: 0.2540, valid_acc: 0.93, lr: 7.4662e-04, et: 0.0665
    epoch 168, train_loss: 0.0126, train_acc: 1.00, valid_loss: 0.2509, valid_acc: 0.93, lr: 7.4388e-04, et: 0.0716
    epoch 169, train_loss: 0.0657, train_acc: 0.96, valid_loss: 0.2674, valid_acc: 0.93, lr: 7.4114e-04, et: 0.0688
    epoch 170, train_loss: 0.0310, train_acc: 1.00, valid_loss: 0.2908, valid_acc: 0.93, lr: 7.3838e-04, et: 0.0681
    epoch 171, train_loss: 0.0624, train_acc: 0.97, valid_loss: 0.2728, valid_acc: 0.93, lr: 7.3562e-04, et: 0.0674
    epoch 172, train_loss: 0.0086, train_acc: 1.00, valid_loss: 0.2563, valid_acc: 0.93, lr: 7.3284e-04, et: 0.0894
    epoch 173, train_loss: 0.0688, train_acc: 0.96, valid_loss: 0.2628, valid_acc: 0.93, lr: 7.3006e-04, et: 0.0832
    epoch 174, train_loss: 0.0887, train_acc: 0.97, valid_loss: 0.2649, valid_acc: 0.90, lr: 7.2727e-04, et: 0.1029
    epoch 175, train_loss: 0.0526, train_acc: 0.97, valid_loss: 0.3100, valid_acc: 0.90, lr: 7.2447e-04, et: 0.0724
    epoch 176, train_loss: 0.0137, train_acc: 1.00, valid_loss: 0.2898, valid_acc: 0.93, lr: 7.2166e-04, et: 0.0731
    epoch 177, train_loss: 0.0065, train_acc: 1.00, valid_loss: 0.2735, valid_acc: 0.93, lr: 7.1884e-04, et: 0.0668
    epoch 178, train_loss: 0.0275, train_acc: 0.97, valid_loss: 0.3083, valid_acc: 0.93, lr: 7.1601e-04, et: 0.0659
    epoch 179, train_loss: 0.0837, train_acc: 0.97, valid_loss: 0.3115, valid_acc: 0.93, lr: 7.1318e-04, et: 0.0655
    epoch 180, train_loss: 0.0282, train_acc: 1.00, valid_loss: 0.2433, valid_acc: 0.93, lr: 7.1033e-04, et: 0.0651
    epoch 181, train_loss: 0.0518, train_acc: 0.99, valid_loss: 0.2535, valid_acc: 0.93, lr: 7.0748e-04, et: 0.0697
    epoch 182, train_loss: 0.0418, train_acc: 0.99, valid_loss: 0.2289, valid_acc: 0.93, lr: 7.0462e-04, et: 0.0677
    epoch 183, train_loss: 0.0449, train_acc: 0.99, valid_loss: 0.2304, valid_acc: 0.93, lr: 7.0175e-04, et: 0.0653
    epoch 184, train_loss: 0.0748, train_acc: 0.97, valid_loss: 0.2506, valid_acc: 0.93, lr: 6.9888e-04, et: 0.0654
    epoch 185, train_loss: 0.0819, train_acc: 0.99, valid_loss: 0.2900, valid_acc: 0.90, lr: 6.9599e-04, et: 0.0651
    epoch 186, train_loss: 0.0168, train_acc: 0.99, valid_loss: 0.2804, valid_acc: 0.90, lr: 6.9310e-04, et: 0.0647
    epoch 187, train_loss: 0.0204, train_acc: 1.00, valid_loss: 0.2641, valid_acc: 0.93, lr: 6.9020e-04, et: 0.0648
    epoch 188, train_loss: 0.0191, train_acc: 1.00, valid_loss: 0.2517, valid_acc: 0.90, lr: 6.8729e-04, et: 0.0646
    epoch 189, train_loss: 0.0940, train_acc: 0.97, valid_loss: 0.2660, valid_acc: 0.90, lr: 6.8438e-04, et: 0.0650
    epoch 190, train_loss: 0.0300, train_acc: 0.99, valid_loss: 0.2397, valid_acc: 0.90, lr: 6.8146e-04, et: 0.0662
    epoch 191, train_loss: 0.0353, train_acc: 0.99, valid_loss: 0.2325, valid_acc: 0.90, lr: 6.7853e-04, et: 0.0650
    epoch 192, train_loss: 0.0107, train_acc: 1.00, valid_loss: 0.2267, valid_acc: 0.90, lr: 6.7559e-04, et: 0.0651
    epoch 193, train_loss: 0.0137, train_acc: 1.00, valid_loss: 0.2294, valid_acc: 0.90, lr: 6.7265e-04, et: 0.0670
    epoch 194, train_loss: 0.0352, train_acc: 0.99, valid_loss: 0.2086, valid_acc: 0.93, lr: 6.6970e-04, et: 0.0649
    epoch 195, train_loss: 0.0259, train_acc: 0.97, valid_loss: 0.2209, valid_acc: 0.93, lr: 6.6674e-04, et: 0.0659
    epoch 196, train_loss: 0.0138, train_acc: 1.00, valid_loss: 0.2358, valid_acc: 0.93, lr: 6.6378e-04, et: 0.0654
    epoch 197, train_loss: 0.0393, train_acc: 0.99, valid_loss: 0.2642, valid_acc: 0.93, lr: 6.6081e-04, et: 0.0644
    epoch 198, train_loss: 0.0349, train_acc: 1.00, valid_loss: 0.3364, valid_acc: 0.90, lr: 6.5784e-04, et: 0.0652
    epoch 199, train_loss: 0.0806, train_acc: 0.96, valid_loss: 0.3652, valid_acc: 0.90, lr: 6.5485e-04, et: 0.0653
    epoch 200, train_loss: 0.0727, train_acc: 0.99, valid_loss: 0.3175, valid_acc: 0.90, lr: 6.5187e-04, et: 0.0651
    epoch 201, train_loss: 0.0483, train_acc: 0.97, valid_loss: 0.2581, valid_acc: 0.93, lr: 6.4887e-04, et: 0.0654
    epoch 202, train_loss: 0.0165, train_acc: 1.00, valid_loss: 0.2687, valid_acc: 0.90, lr: 6.4587e-04, et: 0.0666
    epoch 203, train_loss: 0.0225, train_acc: 1.00, valid_loss: 0.2522, valid_acc: 0.90, lr: 6.4287e-04, et: 0.0650
    epoch 204, train_loss: 0.0160, train_acc: 1.00, valid_loss: 0.2418, valid_acc: 0.90, lr: 6.3986e-04, et: 0.0675
    epoch 205, train_loss: 0.0052, train_acc: 1.00, valid_loss: 0.2268, valid_acc: 0.93, lr: 6.3684e-04, et: 0.0692
    epoch 206, train_loss: 0.0240, train_acc: 0.99, valid_loss: 0.2300, valid_acc: 0.93, lr: 6.3382e-04, et: 0.0646
    epoch 207, train_loss: 0.0676, train_acc: 0.97, valid_loss: 0.2501, valid_acc: 0.93, lr: 6.3079e-04, et: 0.0647
    epoch 208, train_loss: 0.0041, train_acc: 1.00, valid_loss: 0.2820, valid_acc: 0.95, lr: 6.2776e-04, et: 0.0650
    epoch 209, train_loss: 0.0056, train_acc: 1.00, valid_loss: 0.2788, valid_acc: 0.95, lr: 6.2472e-04, et: 0.0656
    epoch 210, train_loss: 0.0318, train_acc: 1.00, valid_loss: 0.2855, valid_acc: 0.93, lr: 6.2168e-04, et: 0.0653
    epoch 211, train_loss: 0.0230, train_acc: 0.99, valid_loss: 0.2575, valid_acc: 0.90, lr: 6.1863e-04, et: 0.0651
    epoch 212, train_loss: 0.0118, train_acc: 1.00, valid_loss: 0.2459, valid_acc: 0.90, lr: 6.1558e-04, et: 0.0654
    epoch 213, train_loss: 0.0337, train_acc: 0.99, valid_loss: 0.2437, valid_acc: 0.93, lr: 6.1252e-04, et: 0.0668
    epoch 214, train_loss: 0.1128, train_acc: 0.94, valid_loss: 0.2407, valid_acc: 0.93, lr: 6.0946e-04, et: 0.0669
    epoch 215, train_loss: 0.0053, train_acc: 1.00, valid_loss: 0.2335, valid_acc: 0.93, lr: 6.0640e-04, et: 0.0662
    epoch 216, train_loss: 0.0062, train_acc: 1.00, valid_loss: 0.2266, valid_acc: 0.95, lr: 6.0333e-04, et: 0.0659
    epoch 217, train_loss: 0.0468, train_acc: 0.99, valid_loss: 0.2388, valid_acc: 0.90, lr: 6.0026e-04, et: 0.0643
    epoch 218, train_loss: 0.0087, train_acc: 1.00, valid_loss: 0.2442, valid_acc: 0.90, lr: 5.9718e-04, et: 0.0650
    epoch 219, train_loss: 0.0062, train_acc: 1.00, valid_loss: 0.2282, valid_acc: 0.93, lr: 5.9410e-04, et: 0.0644
    epoch 220, train_loss: 0.0465, train_acc: 0.99, valid_loss: 0.2173, valid_acc: 0.93, lr: 5.9101e-04, et: 0.0637
    epoch 221, train_loss: 0.0061, train_acc: 1.00, valid_loss: 0.2057, valid_acc: 0.93, lr: 5.8792e-04, et: 0.0640
    epoch 222, train_loss: 0.0296, train_acc: 0.97, valid_loss: 0.2335, valid_acc: 0.93, lr: 5.8483e-04, et: 0.0640
    epoch 223, train_loss: 0.0039, train_acc: 1.00, valid_loss: 0.2399, valid_acc: 0.93, lr: 5.8174e-04, et: 0.0641
    epoch 224, train_loss: 0.0273, train_acc: 0.97, valid_loss: 0.2302, valid_acc: 0.93, lr: 5.7864e-04, et: 0.0645
    epoch 225, train_loss: 0.0071, train_acc: 1.00, valid_loss: 0.2291, valid_acc: 0.93, lr: 5.7554e-04, et: 0.0644
    epoch 226, train_loss: 0.0996, train_acc: 0.93, valid_loss: 0.2160, valid_acc: 0.93, lr: 5.7243e-04, et: 0.0642
    epoch 227, train_loss: 0.0165, train_acc: 1.00, valid_loss: 0.2472, valid_acc: 0.93, lr: 5.6933e-04, et: 0.0649
    epoch 228, train_loss: 0.0284, train_acc: 0.99, valid_loss: 0.2693, valid_acc: 0.93, lr: 5.6622e-04, et: 0.0650
    epoch 229, train_loss: 0.0143, train_acc: 1.00, valid_loss: 0.2615, valid_acc: 0.93, lr: 5.6310e-04, et: 0.0675
    epoch 230, train_loss: 0.0418, train_acc: 0.97, valid_loss: 0.2822, valid_acc: 0.90, lr: 5.5999e-04, et: 0.0651
    epoch 231, train_loss: 0.0300, train_acc: 0.99, valid_loss: 0.2975, valid_acc: 0.90, lr: 5.5687e-04, et: 0.0661
    Early stopping was triggered: epoch #232
    Elapsed Time: 15.34s




.. GENERATED FROM PYTHON SOURCE LINES 171-173

Run the Experiment using Early Stopping with callback_early_stopping
====================================================================

.. GENERATED FROM PYTHON SOURCE LINES 173-227

.. code-block:: Python


    data = torch.load(save_base / "checkpoint" / f"sub-{subject}.pth")
    loss_best = data["loss_best"]

    lr = 1e-4
    weight_decay = 1e-2
    n_epochs = 500
    batch_size = 4
    seed = 42


    def callback_early_stopping(loss_train, loss_valid, epoch):
        return loss_train <= loss_best


    results_2nd_step = rosoku.deeplearning(
        items_train=[subject, "R1", "R2", "R3"],
        items_valid=None,
        items_test=[[subject, "R4", "R5"]],
        callback_load_epochs=functools.partial(
            callback_load_epochs,
            dataset=dataset,
            l_freq=8.0,
            h_freq=30.0,
            order_filter=4,
            tmin=dataset.interval[0] + 0.5,
            tmax=dataset.interval[1],
        ),
        callback_proc_epochs=callback_proc_epochs,
        callback_convert_epochs_to_ndarray=functools.partial(
            convert_epochs_to_ndarray, label_keys=label_keys
        ),
        callback_early_stopping=callback_early_stopping,
        batch_size=batch_size,
        n_epochs=n_epochs,
        criterion=criterion,
        optimizer=optimizer,
        optimizer_params=optimizer_params,
        callback_get_model=callback_get_model,
        scheduler=scheduler,
        scheduler_params=scheduler_params,
        device=device,
        enable_normalization=enable_normalization,
        history_fname=(save_base / "history" / f"sub-{subject}_2nd.parquet"),
        checkpoint_fname=(save_base / "checkpoint" / f"sub-{subject}_2nd.pth"),
        samples_fname=(save_base / "samples" / f"sub-{subject}_2nd.parquet"),
        normalization_fname=(save_base / "normalization" / f"sub-{subject}_2nd.msgpack"),
        saliency_map_fname=(save_base / "saliency" / f"sub-{subject}_2nd.msgpack"),
        label_keys=label_keys,
        seed=seed,
        additional_values={"subject": subject},
    )






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    0it [00:00, ?it/s]    9it [00:00, 21065.14it/s]
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Filtering raw data in 1 contiguous segment
    Setting up band-pass filter from 8 - 30 Hz

    IIR filter parameters
    ---------------------
    Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:
    - Filter order 16 (effective, after forward-backward)
    - Cutoffs at 8.00, 30.00 Hz: -6.02, -6.02 dB

    Used Annotations descriptions: [np.str_('left_hand'), np.str_('right_hand')]
    Ignoring annotation durations and creating fixed-duration epochs around annotation onsets.
    Not setting metadata
    40 matching events found
    No baseline correction applied
    0 projection items activated
    Filtering raw data in 1 contiguous segment
    Setting up band-pass filter from 8 - 30 Hz

    IIR filter parameters
    ---------------------
    Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:
    - Filter order 16 (effective, after forward-backward)
    - Cutoffs at 8.00, 30.00 Hz: -6.02, -6.02 dB

    Used Annotations descriptions: [np.str_('left_hand'), np.str_('right_hand')]
    Ignoring annotation durations and creating fixed-duration epochs around annotation onsets.
    Not setting metadata
    40 matching events found
    No baseline correction applied
    0 projection items activated
    Filtering raw data in 1 contiguous segment
    Setting up band-pass filter from 8 - 30 Hz

    IIR filter parameters
    ---------------------
    Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:
    - Filter order 16 (effective, after forward-backward)
    - Cutoffs at 8.00, 30.00 Hz: -6.02, -6.02 dB

    Used Annotations descriptions: [np.str_('left_hand'), np.str_('right_hand')]
    Ignoring annotation durations and creating fixed-duration epochs around annotation onsets.
    Not setting metadata
    40 matching events found
    No baseline correction applied
    0 projection items activated
    /home/skojima/git/rosoku/examples/02_deeplearning/02_example_2step_early_stopping.py:78: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.
      return mne.concatenate_epochs(epochs_list)
    Using data from preloaded Raw for 40 events and 2305 original time points ...
    0 bad epochs dropped
    Using data from preloaded Raw for 40 events and 2305 original time points ...
    0 bad epochs dropped
    Using data from preloaded Raw for 40 events and 2305 original time points ...
    0 bad epochs dropped
    Using data from preloaded Raw for 40 events and 2305 original time points ...
    Using data from preloaded Raw for 40 events and 2305 original time points ...
    Using data from preloaded Raw for 40 events and 2305 original time points ...
    Not setting metadata
    120 matching events found
    No baseline correction applied
    0it [00:00, ?it/s]    9it [00:00, 24818.37it/s]
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Reading 0 ... 230911  =      0.000 ...   450.998 secs...
    Filtering raw data in 1 contiguous segment
    Setting up band-pass filter from 8 - 30 Hz

    IIR filter parameters
    ---------------------
    Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:
    - Filter order 16 (effective, after forward-backward)
    - Cutoffs at 8.00, 30.00 Hz: -6.02, -6.02 dB

    Used Annotations descriptions: [np.str_('left_hand'), np.str_('right_hand')]
    Ignoring annotation durations and creating fixed-duration epochs around annotation onsets.
    Not setting metadata
    40 matching events found
    No baseline correction applied
    0 projection items activated
    Filtering raw data in 1 contiguous segment
    Setting up band-pass filter from 8 - 30 Hz

    IIR filter parameters
    ---------------------
    Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:
    - Filter order 16 (effective, after forward-backward)
    - Cutoffs at 8.00, 30.00 Hz: -6.02, -6.02 dB

    Used Annotations descriptions: [np.str_('left_hand'), np.str_('right_hand')]
    Ignoring annotation durations and creating fixed-duration epochs around annotation onsets.
    Not setting metadata
    40 matching events found
    No baseline correction applied
    0 projection items activated
    /home/skojima/git/rosoku/examples/02_deeplearning/02_example_2step_early_stopping.py:78: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.
      return mne.concatenate_epochs(epochs_list)
    Using data from preloaded Raw for 40 events and 2305 original time points ...
    0 bad epochs dropped
    Using data from preloaded Raw for 40 events and 2305 original time points ...
    0 bad epochs dropped
    Using data from preloaded Raw for 40 events and 2305 original time points ...
    Using data from preloaded Raw for 40 events and 2305 original time points ...
    Not setting metadata
    80 matching events found
    No baseline correction applied
    epoch 000, train_loss: 0.7141, train_acc: 0.52, lr: 9.9999e-04, et: 0.0799, checkpoint saved
    epoch 001, train_loss: 0.6456, train_acc: 0.64, lr: 9.9996e-04, et: 0.0808, checkpoint saved
    epoch 002, train_loss: 0.6280, train_acc: 0.66, lr: 9.9991e-04, et: 0.0817, checkpoint saved
    epoch 003, train_loss: 0.5808, train_acc: 0.70, lr: 9.9984e-04, et: 0.0826, checkpoint saved
    epoch 004, train_loss: 0.5111, train_acc: 0.80, lr: 9.9975e-04, et: 0.0841, checkpoint saved
    epoch 005, train_loss: 0.4032, train_acc: 0.86, lr: 9.9965e-04, et: 0.0823, checkpoint saved
    epoch 006, train_loss: 0.2703, train_acc: 0.92, lr: 9.9952e-04, et: 0.0829, checkpoint saved
    epoch 007, train_loss: 0.2807, train_acc: 0.93, lr: 9.9937e-04, et: 0.0833
    epoch 008, train_loss: 0.2585, train_acc: 0.89, lr: 9.9920e-04, et: 0.0809, checkpoint saved
    epoch 009, train_loss: 0.2334, train_acc: 0.93, lr: 9.9901e-04, et: 0.0821, checkpoint saved
    epoch 010, train_loss: 0.1748, train_acc: 0.93, lr: 9.9881e-04, et: 0.0854, checkpoint saved
    epoch 011, train_loss: 0.2425, train_acc: 0.88, lr: 9.9858e-04, et: 0.0836
    epoch 012, train_loss: 0.1828, train_acc: 0.95, lr: 9.9833e-04, et: 0.0831
    epoch 013, train_loss: 0.1591, train_acc: 0.94, lr: 9.9807e-04, et: 0.0836, checkpoint saved
    Early stopping was triggered: epoch #14
    Elapsed Time: 1.19s




.. GENERATED FROM PYTHON SOURCE LINES 228-230

Print Results
=============

.. GENERATED FROM PYTHON SOURCE LINES 230-233

.. code-block:: Python


    print(results_1st_step.to_string())
    print(results_2nd_step.to_string())




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

            items_train items_valid        items_test  accuracy   model  subject
    0  [56, "R1", "R2"]  [56, "R3"]  [56, "R4", "R5"]      0.95  EEGNet       56
                  items_train items_valid        items_test  accuracy   model  subject
    0  [56, "R1", "R2", "R3"]        null  [56, "R4", "R5"]       1.0  EEGNet       56





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 20.077 seconds)


.. _sphx_glr_download_auto_examples_02_deeplearning_02_example_2step_early_stopping.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: 02_example_2step_early_stopping.ipynb <02_example_2step_early_stopping.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: 02_example_2step_early_stopping.py <02_example_2step_early_stopping.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: 02_example_2step_early_stopping.zip <02_example_2step_early_stopping.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
