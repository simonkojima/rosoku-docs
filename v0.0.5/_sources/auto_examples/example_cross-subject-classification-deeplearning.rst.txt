
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/example_cross-subject-classification-deeplearning.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_example_cross-subject-classification-deeplearning.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_example_cross-subject-classification-deeplearning.py:


Example: Cross-subject classification with deep learning
========================================================

.. GENERATED FROM PYTHON SOURCE LINES 7-21

.. code-block:: Python

    import functools
    import numpy as np

    from pathlib import Path

    import mne

    import moabb.datasets

    import torch
    import braindecode
    import rosoku









.. GENERATED FROM PYTHON SOURCE LINES 25-82

.. code-block:: Python


    def func_load_ndarray(
            keywords,
            mode,
            tmin,
            tmax,
            l_freq,
            h_freq,
            order_filter,
            label_keys,
            dataset,
    ):
        X_list = []
        y_list = []

        for keyword in keywords:
            subject = int(keyword[1:])
            sessions = dataset.get_data(subjects=[subject])
            raws = sessions[subject]["0"]

            for name, raw in raws.items():
                raw.filter(
                    l_freq=l_freq,
                    h_freq=h_freq,
                    method="iir",
                    iir_params={
                        "ftype": "butter",
                        "order": order_filter,
                        "btype": "bandpass",
                    },
                )

                raw = raw.pick(picks="eeg")

                epochs = mne.Epochs(
                    raw=raw,
                    tmin=tmin,
                    tmax=tmax,
                    baseline=None,
                ).load_data()

                # Apply Domain Adoptation (Euclidean Alignment)
                X = rosoku.tl.euclidean_alignment(epochs.get_data())

                y = rosoku.utils.get_labels_from_epochs(
                    epochs, label_keys=label_keys
                )

                X_list.append(X)
                y_list.append(y)

        X = np.concatenate(X_list, axis=0)
        y = np.concatenate(y_list, axis=0)

        return X, y









.. GENERATED FROM PYTHON SOURCE LINES 83-104

.. code-block:: Python



    def func_get_model(X, y):
        _, n_chans, n_times = X.shape
        F1 = 4
        D = 2
        F2 = F1 * D

        model = braindecode.models.EEGNet(
            n_chans=n_chans,
            n_outputs=2,
            n_times=n_times,
            F1=F1,
            D=D,
            F2=F2,
            drop_prob=0.25,
        )

        return model









.. GENERATED FROM PYTHON SOURCE LINES 105-175

.. code-block:: Python


    lr = 1e-3
    weight_decay = 1e-2
    n_epochs = 500
    batch_size = 64
    patience = 75
    enable_normalization = True
    device = "cuda" if torch.cuda.is_available() else "cpu"
    enable_ddp = False
    enable_dp = False

    seed = 42

    dataset = moabb.datasets.Dreyer2023()

    save_base = Path("~").expanduser() / "rosoku-log"
    (save_base / "checkpoint").mkdir(parents=True, exist_ok=True)
    (save_base / "history").mkdir(parents=True, exist_ok=True)
    (save_base / "saliency").mkdir(parents=True, exist_ok=True)
    (save_base / "samples").mkdir(parents=True, exist_ok=True)
    (save_base / "normalization").mkdir(parents=True, exist_ok=True)

    criterion = torch.nn.CrossEntropyLoss()
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR
    scheduler_params = {"T_max": n_epochs, "eta_min": 1e-6}
    optimizer = torch.optim.AdamW
    optimizer_params = {"lr": lr, "weight_decay": weight_decay}
    early_stopping = rosoku.utils.EarlyStopping(patience=patience)

    label_keys = {"left_hand": 0, "right_hand": 1}

    results = rosoku.deeplearning(
        keywords_train=[f"A{num}" for num in range(1, 16)],
        keywords_valid=[f"A{num}" for num in range(16, 21)],
        keywords_test=["A21", "A56"],
        func_load_ndarray=functools.partial(
            func_load_ndarray,
            dataset=dataset,
            tmin=dataset.interval[0] + 0.5,
            tmax=dataset.interval[1],
            l_freq=8.0,
            h_freq=30.0,
            order_filter=4,
            label_keys=label_keys,
        ),
        batch_size=batch_size,
        n_epochs=n_epochs,
        criterion=criterion,
        optimizer=optimizer,
        optimizer_params=optimizer_params,
        func_get_model=func_get_model,
        scheduler=scheduler,
        scheduler_params=scheduler_params,
        device=device,
        enable_ddp=enable_ddp,
        func_proc_epochs=None,
        early_stopping=early_stopping,
        enable_normalization=enable_normalization,
        name_classifier="eegnet4.2",
        history_fname=(save_base / "history" / f"cross-subject-deeplearning.parquet"),
        checkpoint_fname=(save_base / "checkpoint" / f"cross-subject-deeplearning.pth"),
        samples_fname=(save_base / "samples" / f"cross-subject-deeplearning.parquet"),
        normalization_fname=(save_base / "normalization" / f"cross-subject-deeplearning.msgpack"),
        saliency_map_fname=(save_base / "saliency" / f"cross-subject-deeplearning.msgpack"),
        label_keys=label_keys,
        seed=seed,
    )

    for m in range(results.shape[0]):
        print(results.loc[m])




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    0it [00:00, ?it/s]    9it [00:00, 25420.02it/s]
    0it [00:00, ?it/s]    9it [00:00, 14196.59it/s]
    0it [00:00, ?it/s]    9it [00:00, 18087.56it/s]
    0it [00:00, ?it/s]    9it [00:00, 18513.36it/s]
    0it [00:00, ?it/s]    9it [00:00, 18808.54it/s]
    0it [00:00, ?it/s]    9it [00:00, 15320.10it/s]
    0it [00:00, ?it/s]    9it [00:00, 16138.84it/s]
    0it [00:00, ?it/s]    9it [00:00, 14705.39it/s]
    0it [00:00, ?it/s]    9it [00:00, 17181.95it/s]
    0it [00:00, ?it/s]    9it [00:00, 15981.68it/s]
    0it [00:00, ?it/s]    9it [00:00, 15045.33it/s]
    0it [00:00, ?it/s]    9it [00:00, 15553.66it/s]
    0it [00:00, ?it/s]    9it [00:00, 14027.77it/s]
    0it [00:00, ?it/s]    9it [00:00, 15413.94it/s]
    0it [00:00, ?it/s]    9it [00:00, 14722.60it/s]
    0it [00:00, ?it/s]    9it [00:00, 16441.09it/s]
    0it [00:00, ?it/s]    9it [00:00, 15196.75it/s]
    0it [00:00, ?it/s]    9it [00:00, 14774.46it/s]
    0it [00:00, ?it/s]    9it [00:00, 15735.20it/s]
    0it [00:00, ?it/s]    9it [00:00, 15941.19it/s]
    0it [00:00, ?it/s]    9it [00:00, 17822.82it/s]
    0it [00:00, ?it/s]    9it [00:00, 15496.20it/s]
    epoch 000, train_loss: 0.6914, train_acc: 0.54, valid_loss: 0.6941, valid_acc: 0.46, lr: 9.9999e-04, et: 2.3318, checkpoint saved
    epoch 001, train_loss: 0.6878, train_acc: 0.57, valid_loss: 0.6953, valid_acc: 0.49, lr: 9.9996e-04, et: 2.3205
    epoch 002, train_loss: 0.6821, train_acc: 0.59, valid_loss: 0.6958, valid_acc: 0.50, lr: 9.9991e-04, et: 2.3252
    epoch 003, train_loss: 0.6715, train_acc: 0.62, valid_loss: 0.6966, valid_acc: 0.50, lr: 9.9984e-04, et: 2.3542
    epoch 004, train_loss: 0.6550, train_acc: 0.64, valid_loss: 0.6832, valid_acc: 0.56, lr: 9.9975e-04, et: 2.3316, checkpoint saved
    epoch 005, train_loss: 0.6166, train_acc: 0.70, valid_loss: 0.6201, valid_acc: 0.67, lr: 9.9965e-04, et: 2.3291, checkpoint saved
    epoch 006, train_loss: 0.5527, train_acc: 0.72, valid_loss: 0.5149, valid_acc: 0.73, lr: 9.9952e-04, et: 2.3277, checkpoint saved
    epoch 007, train_loss: 0.5297, train_acc: 0.72, valid_loss: 0.4705, valid_acc: 0.74, lr: 9.9937e-04, et: 2.3290, checkpoint saved
    epoch 008, train_loss: 0.5168, train_acc: 0.74, valid_loss: 0.4694, valid_acc: 0.75, lr: 9.9920e-04, et: 2.3269, checkpoint saved
    epoch 009, train_loss: 0.4945, train_acc: 0.76, valid_loss: 0.4534, valid_acc: 0.76, lr: 9.9901e-04, et: 2.3327, checkpoint saved
    epoch 010, train_loss: 0.5080, train_acc: 0.74, valid_loss: 0.4698, valid_acc: 0.75, lr: 9.9881e-04, et: 2.3704
    epoch 011, train_loss: 0.4773, train_acc: 0.77, valid_loss: 0.4600, valid_acc: 0.75, lr: 9.9858e-04, et: 2.3969
    epoch 012, train_loss: 0.4716, train_acc: 0.77, valid_loss: 0.4617, valid_acc: 0.75, lr: 9.9833e-04, et: 2.4362
    epoch 013, train_loss: 0.4728, train_acc: 0.77, valid_loss: 0.4621, valid_acc: 0.75, lr: 9.9807e-04, et: 2.3729
    epoch 014, train_loss: 0.4646, train_acc: 0.78, valid_loss: 0.4647, valid_acc: 0.74, lr: 9.9778e-04, et: 2.5648
    epoch 015, train_loss: 0.4577, train_acc: 0.78, valid_loss: 0.4605, valid_acc: 0.75, lr: 9.9748e-04, et: 2.3863
    epoch 016, train_loss: 0.5041, train_acc: 0.74, valid_loss: 0.5285, valid_acc: 0.72, lr: 9.9715e-04, et: 2.3743
    epoch 017, train_loss: 0.4733, train_acc: 0.76, valid_loss: 0.4811, valid_acc: 0.74, lr: 9.9681e-04, et: 2.3731
    epoch 018, train_loss: 0.4646, train_acc: 0.77, valid_loss: 0.4829, valid_acc: 0.74, lr: 9.9644e-04, et: 2.3754
    epoch 019, train_loss: 0.4603, train_acc: 0.78, valid_loss: 0.4840, valid_acc: 0.74, lr: 9.9606e-04, et: 2.3698
    epoch 020, train_loss: 0.4660, train_acc: 0.77, valid_loss: 0.4858, valid_acc: 0.74, lr: 9.9566e-04, et: 2.4439
    epoch 021, train_loss: 0.4538, train_acc: 0.78, valid_loss: 0.4845, valid_acc: 0.73, lr: 9.9524e-04, et: 2.3765
    epoch 022, train_loss: 0.4545, train_acc: 0.78, valid_loss: 0.4773, valid_acc: 0.75, lr: 9.9479e-04, et: 2.3530
    epoch 023, train_loss: 0.4565, train_acc: 0.78, valid_loss: 0.4765, valid_acc: 0.75, lr: 9.9433e-04, et: 2.3527
    epoch 024, train_loss: 0.4296, train_acc: 0.80, valid_loss: 0.4611, valid_acc: 0.76, lr: 9.9385e-04, et: 2.3567
    epoch 025, train_loss: 0.4288, train_acc: 0.80, valid_loss: 0.4660, valid_acc: 0.76, lr: 9.9335e-04, et: 2.3542
    epoch 026, train_loss: 0.4477, train_acc: 0.78, valid_loss: 0.4817, valid_acc: 0.74, lr: 9.9283e-04, et: 2.3736
    epoch 027, train_loss: 0.4405, train_acc: 0.79, valid_loss: 0.4909, valid_acc: 0.74, lr: 9.9229e-04, et: 2.3674
    epoch 028, train_loss: 0.4220, train_acc: 0.80, valid_loss: 0.4671, valid_acc: 0.76, lr: 9.9173e-04, et: 2.3691
    epoch 029, train_loss: 0.4173, train_acc: 0.81, valid_loss: 0.4694, valid_acc: 0.76, lr: 9.9115e-04, et: 2.3995
    epoch 030, train_loss: 0.4351, train_acc: 0.79, valid_loss: 0.4739, valid_acc: 0.75, lr: 9.9055e-04, et: 2.3743
    epoch 031, train_loss: 0.4375, train_acc: 0.79, valid_loss: 0.4992, valid_acc: 0.73, lr: 9.8994e-04, et: 2.4701
    epoch 032, train_loss: 0.4133, train_acc: 0.82, valid_loss: 0.4666, valid_acc: 0.76, lr: 9.8930e-04, et: 2.4043
    epoch 033, train_loss: 0.4144, train_acc: 0.82, valid_loss: 0.4763, valid_acc: 0.75, lr: 9.8865e-04, et: 2.3818
    epoch 034, train_loss: 0.4103, train_acc: 0.82, valid_loss: 0.4767, valid_acc: 0.75, lr: 9.8797e-04, et: 2.3719
    epoch 035, train_loss: 0.4099, train_acc: 0.81, valid_loss: 0.4659, valid_acc: 0.76, lr: 9.8728e-04, et: 2.4192
    epoch 036, train_loss: 0.4114, train_acc: 0.82, valid_loss: 0.4787, valid_acc: 0.75, lr: 9.8656e-04, et: 2.4856
    epoch 037, train_loss: 0.4136, train_acc: 0.81, valid_loss: 0.4738, valid_acc: 0.75, lr: 9.8583e-04, et: 2.4736
    epoch 038, train_loss: 0.4045, train_acc: 0.82, valid_loss: 0.4714, valid_acc: 0.75, lr: 9.8508e-04, et: 2.4061
    epoch 039, train_loss: 0.4039, train_acc: 0.82, valid_loss: 0.4771, valid_acc: 0.75, lr: 9.8431e-04, et: 2.3830
    epoch 040, train_loss: 0.4098, train_acc: 0.82, valid_loss: 0.4916, valid_acc: 0.74, lr: 9.8352e-04, et: 2.3744
    epoch 041, train_loss: 0.4197, train_acc: 0.80, valid_loss: 0.4853, valid_acc: 0.74, lr: 9.8271e-04, et: 2.3798
    epoch 042, train_loss: 0.4048, train_acc: 0.82, valid_loss: 0.4765, valid_acc: 0.75, lr: 9.8188e-04, et: 2.3819
    epoch 043, train_loss: 0.4057, train_acc: 0.81, valid_loss: 0.4720, valid_acc: 0.76, lr: 9.8103e-04, et: 2.3808
    epoch 044, train_loss: 0.4077, train_acc: 0.81, valid_loss: 0.4780, valid_acc: 0.76, lr: 9.8017e-04, et: 2.3917
    epoch 045, train_loss: 0.4003, train_acc: 0.82, valid_loss: 0.4818, valid_acc: 0.75, lr: 9.7928e-04, et: 2.4304
    epoch 046, train_loss: 0.4239, train_acc: 0.80, valid_loss: 0.4822, valid_acc: 0.75, lr: 9.7838e-04, et: 2.3997
    epoch 047, train_loss: 0.3972, train_acc: 0.82, valid_loss: 0.4785, valid_acc: 0.76, lr: 9.7745e-04, et: 2.4051
    epoch 048, train_loss: 0.3995, train_acc: 0.82, valid_loss: 0.4809, valid_acc: 0.76, lr: 9.7651e-04, et: 2.3921
    epoch 049, train_loss: 0.4096, train_acc: 0.81, valid_loss: 0.4813, valid_acc: 0.76, lr: 9.7555e-04, et: 2.3875
    epoch 050, train_loss: 0.4015, train_acc: 0.82, valid_loss: 0.4781, valid_acc: 0.76, lr: 9.7457e-04, et: 2.4236
    epoch 051, train_loss: 0.4001, train_acc: 0.82, valid_loss: 0.4928, valid_acc: 0.74, lr: 9.7358e-04, et: 2.3960
    epoch 052, train_loss: 0.3902, train_acc: 0.83, valid_loss: 0.4769, valid_acc: 0.75, lr: 9.7256e-04, et: 2.4988
    epoch 053, train_loss: 0.3957, train_acc: 0.82, valid_loss: 0.4712, valid_acc: 0.76, lr: 9.7152e-04, et: 2.4116
    epoch 054, train_loss: 0.3968, train_acc: 0.82, valid_loss: 0.4816, valid_acc: 0.76, lr: 9.7047e-04, et: 2.3690
    epoch 055, train_loss: 0.3902, train_acc: 0.83, valid_loss: 0.4854, valid_acc: 0.75, lr: 9.6940e-04, et: 2.3762
    epoch 056, train_loss: 0.4025, train_acc: 0.81, valid_loss: 0.4872, valid_acc: 0.75, lr: 9.6831e-04, et: 2.4432
    epoch 057, train_loss: 0.3858, train_acc: 0.83, valid_loss: 0.4930, valid_acc: 0.75, lr: 9.6720e-04, et: 2.3599
    epoch 058, train_loss: 0.3912, train_acc: 0.82, valid_loss: 0.4894, valid_acc: 0.75, lr: 9.6607e-04, et: 2.3973
    epoch 059, train_loss: 0.4073, train_acc: 0.81, valid_loss: 0.4987, valid_acc: 0.75, lr: 9.6492e-04, et: 2.3678
    epoch 060, train_loss: 0.4162, train_acc: 0.80, valid_loss: 0.5013, valid_acc: 0.75, lr: 9.6376e-04, et: 2.4068
    epoch 061, train_loss: 0.3882, train_acc: 0.82, valid_loss: 0.4818, valid_acc: 0.76, lr: 9.6258e-04, et: 2.4182
    epoch 062, train_loss: 0.3868, train_acc: 0.83, valid_loss: 0.4948, valid_acc: 0.75, lr: 9.6138e-04, et: 2.3633
    epoch 063, train_loss: 0.3923, train_acc: 0.82, valid_loss: 0.4797, valid_acc: 0.75, lr: 9.6016e-04, et: 2.3609
    epoch 064, train_loss: 0.4002, train_acc: 0.81, valid_loss: 0.5138, valid_acc: 0.74, lr: 9.5892e-04, et: 2.3817
    epoch 065, train_loss: 0.3885, train_acc: 0.83, valid_loss: 0.4900, valid_acc: 0.75, lr: 9.5766e-04, et: 2.4666
    epoch 066, train_loss: 0.3816, train_acc: 0.83, valid_loss: 0.4847, valid_acc: 0.76, lr: 9.5639e-04, et: 2.4191
    epoch 067, train_loss: 0.3806, train_acc: 0.83, valid_loss: 0.4874, valid_acc: 0.76, lr: 9.5510e-04, et: 2.3701
    epoch 068, train_loss: 0.3802, train_acc: 0.83, valid_loss: 0.4848, valid_acc: 0.76, lr: 9.5379e-04, et: 2.3598
    epoch 069, train_loss: 0.3839, train_acc: 0.83, valid_loss: 0.4926, valid_acc: 0.75, lr: 9.5246e-04, et: 2.3573
    epoch 070, train_loss: 0.3822, train_acc: 0.83, valid_loss: 0.4874, valid_acc: 0.76, lr: 9.5112e-04, et: 2.4043
    epoch 071, train_loss: 0.3759, train_acc: 0.83, valid_loss: 0.4898, valid_acc: 0.75, lr: 9.4975e-04, et: 2.3884
    epoch 072, train_loss: 0.3803, train_acc: 0.83, valid_loss: 0.4961, valid_acc: 0.75, lr: 9.4837e-04, et: 2.4691
    epoch 073, train_loss: 0.3804, train_acc: 0.83, valid_loss: 0.4832, valid_acc: 0.76, lr: 9.4697e-04, et: 2.4356
    epoch 074, train_loss: 0.3829, train_acc: 0.82, valid_loss: 0.5101, valid_acc: 0.74, lr: 9.4556e-04, et: 2.4206
    epoch 075, train_loss: 0.3748, train_acc: 0.83, valid_loss: 0.4905, valid_acc: 0.75, lr: 9.4412e-04, et: 2.3783
    epoch 076, train_loss: 0.3789, train_acc: 0.83, valid_loss: 0.5070, valid_acc: 0.74, lr: 9.4267e-04, et: 2.4433
    epoch 077, train_loss: 0.3758, train_acc: 0.83, valid_loss: 0.4954, valid_acc: 0.74, lr: 9.4120e-04, et: 2.4146
    epoch 078, train_loss: 0.3814, train_acc: 0.83, valid_loss: 0.4887, valid_acc: 0.75, lr: 9.3972e-04, et: 2.3738
    epoch 079, train_loss: 0.3924, train_acc: 0.81, valid_loss: 0.4959, valid_acc: 0.75, lr: 9.3822e-04, et: 2.3561
    epoch 080, train_loss: 0.3805, train_acc: 0.83, valid_loss: 0.4925, valid_acc: 0.75, lr: 9.3669e-04, et: 2.3703
    epoch 081, train_loss: 0.3749, train_acc: 0.83, valid_loss: 0.4931, valid_acc: 0.75, lr: 9.3516e-04, et: 2.3688
    epoch 082, train_loss: 0.3724, train_acc: 0.83, valid_loss: 0.4924, valid_acc: 0.75, lr: 9.3360e-04, et: 2.3587
    epoch 083, train_loss: 0.3751, train_acc: 0.83, valid_loss: 0.4918, valid_acc: 0.75, lr: 9.3203e-04, et: 2.3617
    epoch 084, train_loss: 0.3778, train_acc: 0.83, valid_loss: 0.5062, valid_acc: 0.75, lr: 9.3044e-04, et: 2.3586
    Early stopping was triggered: epoch #85
    Elapsed Time: 203.06s
    keywords_train    ["A1", "A2", "A3", "A4", "A5", "A6", "A7", "A8...
    keywords_valid                  ["A16", "A17", "A18", "A19", "A20"]
    keywords_test                                                 "A21"
    classifier                                                eegnet4.2
    accuracy                                                   0.608333
    Name: 0, dtype: object
    keywords_train    ["A1", "A2", "A3", "A4", "A5", "A6", "A7", "A8...
    keywords_valid                  ["A16", "A17", "A18", "A19", "A20"]
    keywords_test                                                 "A56"
    classifier                                                eegnet4.2
    accuracy                                                      0.975
    Name: 1, dtype: object





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (4 minutes 10.304 seconds)


.. _sphx_glr_download_auto_examples_example_cross-subject-classification-deeplearning.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: example_cross-subject-classification-deeplearning.ipynb <example_cross-subject-classification-deeplearning.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: example_cross-subject-classification-deeplearning.py <example_cross-subject-classification-deeplearning.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: example_cross-subject-classification-deeplearning.zip <example_cross-subject-classification-deeplearning.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
